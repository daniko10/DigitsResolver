{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "n-Uok6rrlDLQ"
      },
      "outputs": [],
      "source": [
        "# Basic imports\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import subprocess\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import ConcatDataset, DataLoader\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPShallow(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLPShallow, self).__init__()\n",
        "\n",
        "        self.input_layer = nn.Linear(784, 256)\n",
        "        self.batch_norm_1 = nn.BatchNorm1d(256)  # BatchNorm po warstwie wejściowej\n",
        "        self.dropout_1 = nn.Dropout(0.2)  # Dropout z prawdopodobieństwem 20%\n",
        "\n",
        "        self.hidden_layer_1 = nn.Linear(256, 256)\n",
        "        self.batch_norm_2 = nn.BatchNorm1d(256)\n",
        "        self.dropout_2 = nn.Dropout(0.2)\n",
        "\n",
        "        self.hidden_layer_2 = nn.Linear(256, 128)\n",
        "        self.batch_norm_3 = nn.BatchNorm1d(128)\n",
        "        self.dropout_3 = nn.Dropout(0.2)\n",
        "\n",
        "        self.hidden_layer_3 = nn.Linear(128, 64)\n",
        "        self.batch_norm_4 = nn.BatchNorm1d(64)\n",
        "        self.dropout_4 = nn.Dropout(0.2)\n",
        "\n",
        "        self.hidden_layer_4 = nn.Linear(64, 32)\n",
        "        self.batch_norm_5 = nn.BatchNorm1d(32)\n",
        "        self.dropout_5 = nn.Dropout(0.2)\n",
        "\n",
        "        self.hidden_layer_5 = nn.Linear(32, 16)\n",
        "        self.batch_norm_6 = nn.BatchNorm1d(16)\n",
        "        self.dropout_6 = nn.Dropout(0.2)\n",
        "\n",
        "        self.output_layer = nn.Linear(16, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.batch_norm_1(self.input_layer(x)))\n",
        "        x = self.dropout_1(x)\n",
        "\n",
        "        x = F.relu(self.batch_norm_2(self.hidden_layer_1(x)))\n",
        "        x = self.dropout_2(x)\n",
        "\n",
        "        x = F.relu(self.batch_norm_3(self.hidden_layer_2(x)))\n",
        "        x = self.dropout_3(x)\n",
        "\n",
        "        x = F.relu(self.batch_norm_4(self.hidden_layer_3(x)))\n",
        "        x = self.dropout_4(x)\n",
        "\n",
        "        x = F.relu(self.batch_norm_5(self.hidden_layer_4(x)))\n",
        "        x = self.dropout_5(x)\n",
        "\n",
        "        x = F.relu(self.batch_norm_6(self.hidden_layer_5(x)))\n",
        "        x = self.dropout_6(x)\n",
        "\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "model = MLPShallow()"
      ],
      "metadata": {
        "id": "X34aI10BlFUw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# please consult torchvision here: https://pytorch.org/vision/stable/index.html\n",
        "def to_binary(image):\n",
        "    # Przekształcenie obrazu na wartości binarne: 0 (czarny) i 1 (biały)\n",
        "    threshold = 0.5  # Ustal próg, gdzie wartości poniżej 0.5 będą czarne, a powyżej białe\n",
        "    return (image > 0).float()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),  # Konwersja na czarno-biały obraz\n",
        "    transforms.ToTensor(),  # Konwersja do tensora\n",
        "    transforms.Normalize((0.5,), (0.5,)),  # Normalizacja\n",
        "    transforms.Lambda(to_binary)\n",
        "])\n",
        "\n",
        "# first we get the training dataset from touchvision\n",
        "training_data_mnist = torchvision.datasets.MNIST(root=\"../data\", train=True, transform=transform, download=True)\n",
        "test_data_mnist = torchvision.datasets.MNIST(root=\"../data\", train=False, transform=transform, download=True)\n",
        "\n",
        "# EMNIST Dataset (split \"digits\" dla cyfr 0-9)\n",
        "training_data_emnist = torchvision.datasets.EMNIST(root=\"../data\", split=\"digits\", train=True, transform=transform, download=True)\n",
        "test_data_emnist = torchvision.datasets.EMNIST(root=\"../data\", split=\"digits\", train=False, transform=transform, download=True)\n",
        "\n",
        "# Połączenie wszystkich zbiorów cyfr\n",
        "full_dataset_train = ConcatDataset([training_data_mnist, training_data_emnist])\n",
        "full_dataset_test = ConcatDataset([test_data_mnist, test_data_emnist])\n",
        "\n",
        "# Tworzenie DataLoadera\n",
        "batch_size = 64\n",
        "data_loader_train = DataLoader(full_dataset_train, batch_size=batch_size, shuffle=True)\n",
        "data_loader_test = DataLoader(full_dataset_test, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "UUFwMN7FlHJB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a loss function\n",
        "\n",
        "# note!! in pytorch the CrossEntropyLoss will apply softmax internally...\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "-jSErKlMlKlC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Epochs = 3\n",
        "for epoch in range(Epochs):\n",
        "  training_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for i, data in enumerate(data_loader_train, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.view(inputs.shape[0], -1)\n",
        "    # Flatten the images\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_function(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    training_loss += loss.item()\n",
        "    _, predicted = outputs.max(1)\n",
        "    total += labels.size(0)\n",
        "    correct += predicted.eq(labels).sum().item()\n",
        "    avg_loss = training_loss / (i + 1)\n",
        "    avg_acc = 100. * correct / total\n",
        "  print(f'Training Loss: {avg_loss:.3f} | Training acc: {avg_acc:.3f}', 'for epoch: ', epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFRDeQoGlMcL",
        "outputId": "6892665c-05b5-4517-b3bc-1ef7b97127bb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.481 | Training acc: 87.699 for epoch:  0\n",
            "Training Loss: 0.266 | Training acc: 93.440 for epoch:  1\n",
            "Training Loss: 0.225 | Training acc: 94.519 for epoch:  2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'cnn_6.pth')\n",
        "print(\"Model saved to 'cnn.pth'\")"
      ],
      "metadata": {
        "id": "YJXohrBcmLWY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c949ce7-bc10-4877-c6cd-5d5a87d1b16c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to 'cnn.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for i, (image, label) in enumerate(data_loader_test):\n",
        "      image = image.view(image.shape[0], -1)\n",
        "      output = model(image)\n",
        "      test_loss += F.nll_loss(output, label, reduction='sum').item()\n",
        "      #test_loss += F.nll_loss(output, label, size_average=False).item()\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(label.data.view_as(pred)).sum()\n",
        "    test_loss /= len(data_loader_test.dataset)\n",
        "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(data_loader_test.dataset), 100. * correct / len(data_loader_test.dataset)))"
      ],
      "metadata": {
        "id": "2labjVd2mNKw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3786791c-dfc2-4a14-99a7-23eed3f11235"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Avg. loss: -7.0817, Accuracy: 48826/50000 (98%)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}